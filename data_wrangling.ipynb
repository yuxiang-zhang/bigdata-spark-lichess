{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def init_spark():\n",
    "    return SparkSession \\\n",
    "        .builder \\\n",
    "        .master(\"local[4]\") \\\n",
    "        .appName(\"Chess Preprocess\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark = init_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/games.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "import pyspark.pandas as ps\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         id  rated    created_at  last_move_at  turns victory_status winner  \\\n0  TZJHLljE  False  1.504210e+12  1.504210e+12     13      outoftime  white   \n1  l1NXvwaE   True  1.504130e+12  1.504130e+12     16         resign  black   \n2  mIICvQHh   True  1.504130e+12  1.504130e+12     61           mate  white   \n3  kWKvrqYL   True  1.504110e+12  1.504110e+12     61           mate  white   \n4  9tXo1AUZ   True  1.504030e+12  1.504030e+12     95           mate  white   \n\n  increment_code       white_id  white_rating      black_id  black_rating  \\\n0           15+2       bourgris          1500          a-00          1191   \n1           5+10           a-00          1322     skinnerua          1261   \n2           5+10         ischia          1496          a-00          1500   \n3           20+0  daniamurashov          1439  adivanov2009          1454   \n4           30+3      nik221107          1523  adivanov2009          1469   \n\n                                               moves opening_eco  \\\n0  d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...         D10   \n1  d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...         B00   \n2  e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...         C20   \n3  d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...         D02   \n4  e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...         C41   \n\n                             opening_name  opening_ply  \n0        Slav Defense: Exchange Variation            5  \n1  Nimzowitsch Defense: Kennedy Variation            4  \n2   King's Pawn Game: Leonardis Variation            3  \n3  Queen's Pawn Game: Zukertort Variation            3  \n4                        Philidor Defense            5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>rated</th>\n      <th>created_at</th>\n      <th>last_move_at</th>\n      <th>turns</th>\n      <th>victory_status</th>\n      <th>winner</th>\n      <th>increment_code</th>\n      <th>white_id</th>\n      <th>white_rating</th>\n      <th>black_id</th>\n      <th>black_rating</th>\n      <th>moves</th>\n      <th>opening_eco</th>\n      <th>opening_name</th>\n      <th>opening_ply</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TZJHLljE</td>\n      <td>False</td>\n      <td>1.504210e+12</td>\n      <td>1.504210e+12</td>\n      <td>13</td>\n      <td>outoftime</td>\n      <td>white</td>\n      <td>15+2</td>\n      <td>bourgris</td>\n      <td>1500</td>\n      <td>a-00</td>\n      <td>1191</td>\n      <td>d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...</td>\n      <td>D10</td>\n      <td>Slav Defense: Exchange Variation</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>l1NXvwaE</td>\n      <td>True</td>\n      <td>1.504130e+12</td>\n      <td>1.504130e+12</td>\n      <td>16</td>\n      <td>resign</td>\n      <td>black</td>\n      <td>5+10</td>\n      <td>a-00</td>\n      <td>1322</td>\n      <td>skinnerua</td>\n      <td>1261</td>\n      <td>d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...</td>\n      <td>B00</td>\n      <td>Nimzowitsch Defense: Kennedy Variation</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mIICvQHh</td>\n      <td>True</td>\n      <td>1.504130e+12</td>\n      <td>1.504130e+12</td>\n      <td>61</td>\n      <td>mate</td>\n      <td>white</td>\n      <td>5+10</td>\n      <td>ischia</td>\n      <td>1496</td>\n      <td>a-00</td>\n      <td>1500</td>\n      <td>e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...</td>\n      <td>C20</td>\n      <td>King's Pawn Game: Leonardis Variation</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>kWKvrqYL</td>\n      <td>True</td>\n      <td>1.504110e+12</td>\n      <td>1.504110e+12</td>\n      <td>61</td>\n      <td>mate</td>\n      <td>white</td>\n      <td>20+0</td>\n      <td>daniamurashov</td>\n      <td>1439</td>\n      <td>adivanov2009</td>\n      <td>1454</td>\n      <td>d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...</td>\n      <td>D02</td>\n      <td>Queen's Pawn Game: Zukertort Variation</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9tXo1AUZ</td>\n      <td>True</td>\n      <td>1.504030e+12</td>\n      <td>1.504030e+12</td>\n      <td>95</td>\n      <td>mate</td>\n      <td>white</td>\n      <td>30+3</td>\n      <td>nik221107</td>\n      <td>1523</td>\n      <td>adivanov2009</td>\n      <td>1469</td>\n      <td>e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...</td>\n      <td>C41</td>\n      <td>Philidor Defense</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Inspect Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[('id', 'string'),\n ('rated', 'boolean'),\n ('created_at', 'double'),\n ('last_move_at', 'double'),\n ('turns', 'int'),\n ('victory_status', 'string'),\n ('winner', 'string'),\n ('increment_code', 'string'),\n ('white_id', 'string'),\n ('white_rating', 'int'),\n ('black_id', 'string'),\n ('black_rating', 'int'),\n ('moves', 'string'),\n ('opening_eco', 'string'),\n ('opening_name', 'string'),\n ('opening_ply', 'int')]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categorical = [feature for feature, dtype in df.dtypes if dtype in {'string', 'boolean'}]\n",
    "numerical = [feature for feature, dtype in df.dtypes if dtype in {'double', 'int'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_at          :13151 unique values\n",
      "last_move_at        :13186 unique values\n",
      "turns               :211 unique values\n",
      "white_rating        :1516 unique values\n",
      "black_rating        :1521 unique values\n",
      "opening_ply         :[28, 12, 1, 13, 6, 16, 3, 20, 5, 19, 15, 9, 17, 4, 8, 7, 10, 11, 14, 2, 18, 22, 24]\n"
     ]
    }
   ],
   "source": [
    "for col in numerical:\n",
    "    unique_values = df.select(col).distinct()\n",
    "    n_unique = unique_values.count()\n",
    "    if n_unique < 50:\n",
    "        print(f'{col:20s}:{[row[col] for row in unique_values.collect()]}')\n",
    "    else:\n",
    "        print(f'{col:20s}:{n_unique} unique values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- `created_at`: Timestamp in UTC\n",
    "- `last_move_at`: Timestamp in UTC\n",
    "- `turns`: Number of turns in the match\n",
    "- `white_rating`: white player rating\n",
    "- `black_rating`: black player rating\n",
    "- `opening_ply`: Number of plies used to set up opening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                  :19113 unique values\n",
      "rated               :[True, False]\n",
      "victory_status      :['resign', 'outoftime', 'mate', 'draw']\n",
      "winner              :['white', 'black', 'draw']\n",
      "increment_code      :400 unique values\n",
      "white_id            :9438 unique values\n",
      "black_id            :9331 unique values\n",
      "moves               :18920 unique values\n",
      "opening_eco         :365 unique values\n",
      "opening_name        :1477 unique values\n"
     ]
    }
   ],
   "source": [
    "for col in categorical:\n",
    "    unique_values = df.select(col).distinct()\n",
    "    n_unique = unique_values.count()\n",
    "    if n_unique < 50:\n",
    "        print(f'{col:20s}:{[row[col] for row in unique_values.collect()]}')\n",
    "    else:\n",
    "        print(f'{col:20s}:{n_unique} unique values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- `id`: Game ID, uniquely identifies a match record\n",
    "- `rated`: If rated, the game result affects player ratings\n",
    "- `victory_status`: How the game ended\n",
    "- `winner`: Match winner\n",
    "- `increment_code`: Game time setting\n",
    "- `white_id`: white player id\n",
    "- `black_id`: black player id\n",
    "- `moves`: Sequence of moves recorded during the match\n",
    "- `opening_eco`: ECO classification code for the chess openings moves\n",
    "- `opening_name`: Name of opening moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Look for Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique samples / total samples: 19629 / 20058 \n"
     ]
    }
   ],
   "source": [
    "print( f'unique samples / total samples: {df.distinct().count()} / {df.count()} ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Null Values in each Column\n"
     ]
    },
    {
     "data": {
      "text/plain": "   id  rated  created_at  last_move_at  turns  victory_status  winner  \\\n0   0      0           0             0      0               0       0   \n\n   increment_code  white_id  white_rating  black_id  black_rating  moves  \\\n0               0         0             0         0             0      0   \n\n   opening_eco  opening_name  opening_ply  \n0            0             0            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>rated</th>\n      <th>created_at</th>\n      <th>last_move_at</th>\n      <th>turns</th>\n      <th>victory_status</th>\n      <th>winner</th>\n      <th>increment_code</th>\n      <th>white_id</th>\n      <th>white_rating</th>\n      <th>black_id</th>\n      <th>black_rating</th>\n      <th>moves</th>\n      <th>opening_eco</th>\n      <th>opening_name</th>\n      <th>opening_ply</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Count Null Values in each Column')\n",
    "df.select([F.count(F.when(F.isnull(col), col)).alias(col) for col in df.columns]).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- There are duplicate rows, which should be dropped from the dataset.\n",
    "- Luckily, this dataset does not contain missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Preparation (Preprocessing)\n",
    "Scikit-Learn offers a range of useful methods for preprocessing and data splits. With the approval from the course instructor, we will transform the datasets into *Pandas DataFrames* in this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Fix Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Drop Duplicates\n",
    "df = df.distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Label `winner`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|winner|winner_label|\n",
      "+------+------------+\n",
      "|  draw|         2.0|\n",
      "| white|         0.0|\n",
      "| black|         1.0|\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_indexer = StringIndexer(inputCol='winner', outputCol='winner_label')\n",
    "label_indexer_model = label_indexer.fit(df)\n",
    "df = label_indexer_model.transform(df)\n",
    "df.select('winner', 'winner_label').distinct().show()\n",
    "df = df.drop('winner').withColumnRenamed('winner_label', 'winner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature `increment_code`\n",
    "As per inspection, the feature contains a string with two numbers separated by `+`. After research, we found that the first number refers to initial total clock time per player in *minutes*; the second number refers to the number of *seconds* added to the total clock time after the player makes a move. We decided to extract these two numbers as two separate features `clock` and `increment` replacing `increment_code`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(increment_code='30+25'),\n Row(increment_code='10+0'),\n Row(increment_code='10+3')]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('increment_code').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(clock=5, increment=60),\n Row(clock=8, increment=0),\n Row(clock=3, increment=10)]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = F.split(df.increment_code, '[+]')\n",
    "df = df.withColumn('clock', splits.getItem(0).cast('Integer')).withColumn('increment', splits.getItem(1).cast('Integer'))\n",
    "df.select('clock', 'increment').tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature `opening_eco`\n",
    "As per inspection, each row of this feature is a concatenation of a letter that denotes an [opening moves category](https://www.365chess.com/eco.php). Although there are variations within each category, we assume that the opening moves in each category to be similar enough that we can ignore the differences within each opening move category. Therefore, we extract the first letter from `opening_eco` to a new feature `open_cat` and ignore `opening_eco` during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(opening_eco='B11'), Row(opening_eco='B45'), Row(opening_eco='C60')]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('opening_eco').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|open_category|\n",
      "+-------------+\n",
      "|            E|\n",
      "|            B|\n",
      "|            D|\n",
      "|            C|\n",
      "|            A|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('open_category', df.opening_eco.substr(0, 1))\n",
    "df.select('open_category').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|open_category|open_cat|\n",
      "+-------------+--------+\n",
      "|            D|     3.0|\n",
      "|            B|     1.0|\n",
      "|            E|     4.0|\n",
      "|            C|     0.0|\n",
      "|            A|     2.0|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "open_cat_indexer = StringIndexer(inputCol='open_category', outputCol='open_cat')\n",
    "open_cat_model = open_cat_indexer.fit(df)\n",
    "df = open_cat_model.transform(df)\n",
    "df.select('open_category', 'open_cat').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature `rated`\n",
    "Contains boolean values only and does not require preprocessing. Rated games affect player ratings and may affect performance of the player. We may choose to separate rated games from unrated games for this fact, here we did not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Split into Train/Test Sets\n",
    "1. Encode player ids into numerical values.\n",
    "    - Ensure that each player is assigned one and only one numerical id.\n",
    "2. Use encoded player ids to split dataset based on groups.\n",
    "    - Each group contains the matches played by one player. Make sure that each group are sampled evenly in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Scikit-Learn Split methods cannot handle distributed datasets. Because we want to leverage the `GroupSplit` method in Scikit-Learn, we are turning the Spark DF into Pandas DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_pd = df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Encode categorical player `white_id`s `black_id`s to split based on individual players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                  white_id  white_id_num        black_id  black_id_num\n0                 konst767             0    ducksandcats             1\n1      everybodylovesjesus             2          ahmd11             3\n2                 jeff1983             4       bekzodjon             5\n3                 mellowg7             6        jesteroz             7\n4                 omnivoid             8  hasan_al-banna             9\n...                    ...           ...             ...           ...\n19624     demontechristo66          9815           eie24          3698\n19625         r-mohamadi55         15633           eie24          3698\n19626           kastorcito          5322            ed84          4132\n19627                 ssf7          3469            casr         15634\n19628                vares          4045        seciyeli          4932\n\n[19629 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>white_id</th>\n      <th>white_id_num</th>\n      <th>black_id</th>\n      <th>black_id_num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>konst767</td>\n      <td>0</td>\n      <td>ducksandcats</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>everybodylovesjesus</td>\n      <td>2</td>\n      <td>ahmd11</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>jeff1983</td>\n      <td>4</td>\n      <td>bekzodjon</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mellowg7</td>\n      <td>6</td>\n      <td>jesteroz</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>omnivoid</td>\n      <td>8</td>\n      <td>hasan_al-banna</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19624</th>\n      <td>demontechristo66</td>\n      <td>9815</td>\n      <td>eie24</td>\n      <td>3698</td>\n    </tr>\n    <tr>\n      <th>19625</th>\n      <td>r-mohamadi55</td>\n      <td>15633</td>\n      <td>eie24</td>\n      <td>3698</td>\n    </tr>\n    <tr>\n      <th>19626</th>\n      <td>kastorcito</td>\n      <td>5322</td>\n      <td>ed84</td>\n      <td>4132</td>\n    </tr>\n    <tr>\n      <th>19627</th>\n      <td>ssf7</td>\n      <td>3469</td>\n      <td>casr</td>\n      <td>15634</td>\n    </tr>\n    <tr>\n      <th>19628</th>\n      <td>vares</td>\n      <td>4045</td>\n      <td>seciyeli</td>\n      <td>4932</td>\n    </tr>\n  </tbody>\n</table>\n<p>19629 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_ids = pd.DataFrame(df_pd[['white_id', 'black_id']])\n",
    "player_ids = player_ids.stack().pipe(lambda s: pd.Series(pd.factorize(s.values)[0], s.index)).unstack()\n",
    "\n",
    "df_pd['white_id_num'] = player_ids['white_id']\n",
    "df_pd['black_id_num'] = player_ids['black_id']\n",
    "\n",
    "df_pd[['white_id', 'white_id_num', 'black_id', 'black_id_num']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "train_idx, test_idx = next(gss.split(df_pd, df_pd['winner'], groups=df_pd['white_id_num']))\n",
    "\n",
    "df_train = df_pd.iloc[train_idx]\n",
    "\n",
    "df_test = df_pd.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Proof that none of the IDs from the training set are present in the test set.\n",
    "df_train_values = set(df_train['white_id'].values)\n",
    "df_test_values = set(df_test['white_id'].values)\n",
    "\n",
    "assert len(df_train_values.intersection(df_test_values)) == 0, 'A group is present in both training and test sets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature `victory_status`\n",
    "From inspection, we observe 4 unique values for this categorical feature: `'resign', 'outoftime', 'mate', 'draw'`. We perform one-hot encoding before feeding this into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['status_draw', 'status_mate', 'status_outoftime', 'status_resign'],\n      dtype=object)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(sparse=False, dtype=int, handle_unknown='ignore')\n",
    "enc.fit(df_train['victory_status'].to_numpy().reshape(-1, 1))\n",
    "encoded_feature_names = 'status_' + enc.categories_[0]\n",
    "encoded_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuxiang\\AppData\\Local\\Temp\\ipykernel_4584\\2844110880.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:,encoded_feature_names] = one_hot_status\n",
      "C:\\Users\\yuxiang\\AppData\\Local\\Temp\\ipykernel_4584\\2844110880.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.loc[:,encoded_feature_names] = one_hot_status\n"
     ]
    },
    {
     "data": {
      "text/plain": "   status_draw  status_mate  status_outoftime  status_resign\n0            0            0                 0              1\n1            0            0                 0              1\n3            0            1                 0              0\n4            0            0                 0              1\n6            0            0                 0              1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>status_draw</th>\n      <th>status_mate</th>\n      <th>status_outoftime</th>\n      <th>status_resign</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_status = enc.transform(df_train['victory_status'].to_numpy().reshape(-1, 1))\n",
    "df_train.loc[:,encoded_feature_names] = one_hot_status\n",
    "\n",
    "one_hot_status = enc.transform(df_test['victory_status'].to_numpy().reshape(-1, 1))\n",
    "df_test.loc[:,encoded_feature_names] = one_hot_status\n",
    "df_train[encoded_feature_names].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create Spark DF from Pandas DF Train/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train = spark.createDataFrame(df_train)\n",
    "\n",
    "df_test = spark.createDataFrame(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature `moves`\n",
    "As per inspection, this feature records the list/sequence of moves during the match. Because that the sequence, if parsed correctly, actually indicates the winning player, we need to either drop this feature or obfuscate this information. We find that Spark supports Word2Vec feature transformation, which will turn the sequence into a vector. Such vector representation is independent of the order of the moves, and this can obfuscate part of the information lied within this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'e4 c6 Nc3 d5 Nf3 Bg4 h3 Bh5 exd5 cxd5 Bb5+ Nc6 g4 Bg6 Ne5 Qb6 Nxg6 hxg6 Nxd5 Qc5 Qf3 Rc8 Nc3 e6 d3 Qe5+ Qe4 Bd6 Be3 Ne7 Bd4 Qxe4+ Nxe4 Bb8 Bxg7 Rh4 Bf6 Rh6'"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.select('moves').head().moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vectorSize = 100\n",
    "word2Vec = Word2Vec(vectorSize=vectorSize, seed=seed, inputCol=\"moves_list\", outputCol=\"moves_vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for `Word2Vec`\n",
    "- `vectorSize`: size of the output vector, the choice of 100 is arbitrary here\n",
    "- `minCount`: Ignores all words with total frequency lower than this.\n",
    "- `inputCol`: `moves_list` is the input feature, a list of `moves` split by space\n",
    "- `outputCol`: `moves_vec` is the output feature, the transformed vector\n",
    "\n",
    "The Word2Vec model will be trained with the corpus gathered from the `moves` in the training set. After which, it will transform both training and testing datasets' `moves` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[moves_list: array<string>]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split moves from string into list of strings, moves -> [move, move, ...]\n",
    "train_moves_corpus = df_train.select(F.split(df_train.moves, '\\s', -1).alias('moves_list'))\n",
    "train_moves_corpus #.collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Word2Vec Model\n",
      "+-----+--------------------+\n",
      "| word|              vector|\n",
      "+-----+--------------------+\n",
      "| Bxd2|[0.08646679669618...|\n",
      "| Nxf6|[-0.3127570748329...|\n",
      "|  a2+|[0.02550127729773...|\n",
      "|Bxd5+|[0.14410454034805...|\n",
      "|  Kg8|[-0.1851859688758...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\envs\\bigdata\\lib\\site-packages\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fitted_word2Vec = word2Vec.fit(train_moves_corpus)\n",
    "print('Trained Word2Vec Model')\n",
    "fitted_word2Vec.getVectors().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "('Transformed Moves for the 1st Match in Training Set: ',\n DenseVector([0.1149, 0.0761, 0.019, 0.0671, -0.1265, -0.0495, -0.0001, 0.0269, -0.0027, 0.0543, -0.0921, -0.043, 0.0581, 0.0162, -0.0572, -0.0128, 0.0236, -0.0254, 0.0416, 0.104, -0.0107, -0.0327, -0.0123, -0.0158, -0.0854, -0.0706, -0.1003, -0.0493, 0.0998, -0.0557, 0.025, 0.0252, 0.0767, -0.0238, 0.1444, 0.1162, -0.0034, 0.0435, -0.0162, -0.1023, -0.0363, 0.0349, -0.0397, -0.0861, -0.1683, -0.1017, -0.0548, 0.0306, -0.0268, 0.0998, -0.0735, 0.0093, 0.0021, -0.0197, -0.0052, 0.0371, 0.033, 0.0168, -0.0196, 0.0726, -0.0009, 0.0104, -0.0574, 0.0021, -0.0818, -0.0809, 0.0882, 0.0114, -0.0434, -0.0145, 0.0182, -0.0209, -0.0122, 0.1118, 0.0584, -0.0295, -0.0278, -0.0114, 0.115, 0.1062, -0.0852, -0.0015, 0.0958, 0.0385, -0.0011, 0.0064, 0.0006, -0.0648, 0.0568, -0.0183, -0.0443, -0.1293, 0.0597, 0.0492, -0.0374, -0.133, 0.0243, -0.056, 0.0682, 0.0676]))"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Transformed Moves for the 1st Match in Training Set: ', fitted_word2Vec.transform(train_moves_corpus).head().moves_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train.withColumn('moves_list', F.split(df_train.moves, '\\s', -1))\n",
    "df_train = fitted_word2Vec.transform(df_train)\n",
    "\n",
    "df_test = df_test.withColumn('moves_list', F.split(df_test.moves, '\\s', -1))\n",
    "df_test = fitted_word2Vec.transform(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Save Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train.toPandas().to_csv('data/train.csv', index=False)\n",
    "df_test.toPandas().to_csv('data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification Problem\n",
    " In a new match between two players, who is most likely to win?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "('rated',\n 'turns',\n 'status_draw',\n 'status_mate',\n 'status_resign',\n 'status_outoftime',\n 'clock',\n 'increment',\n 'white_rating',\n 'black_rating',\n 'open_cat',\n 'opening_ply',\n 'moves_vec',\n 'winner')"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = 'rated', 'turns', 'status_draw', 'status_mate', 'status_resign', 'status_outoftime', 'clock', 'increment', 'white_rating', 'black_rating', 'open_cat', 'opening_ply', 'moves_vec'\n",
    "target = 'winner',\n",
    "inputColumns = features + target\n",
    "inputColumns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "training_assembler = VectorAssembler(handleInvalid='error', inputCols=features, outputCol='features')\n",
    "test_assembler = VectorAssembler(handleInvalid='error', inputCols=features, outputCol='features')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "clf_train_df = training_assembler.transform(df_train.select(*inputColumns)).select('features', *target)\n",
    "clf_test_df = test_assembler.transform(df_test.select(*inputColumns)).select('features', *target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regression Problem\n",
    " Can a player's rating be determined from a single match record with another player?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "('rated',\n 'turns',\n 'status_draw',\n 'status_mate',\n 'status_resign',\n 'status_outoftime',\n 'clock',\n 'increment',\n 'white_rating',\n 'open_cat',\n 'opening_ply',\n 'moves_vec',\n 'winner',\n 'black_rating')"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = 'rated', 'turns', 'status_draw', 'status_mate', 'status_resign', 'status_outoftime', 'clock', 'increment', 'white_rating', 'open_cat', 'opening_ply', 'moves_vec', 'winner',\n",
    "target = 'black_rating', \n",
    "inputColumns = features + target\n",
    "inputColumns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "training_assembler = VectorAssembler(handleInvalid='error', inputCols=features, outputCol='features')\n",
    "test_assembler = VectorAssembler(handleInvalid='error', inputCols=features, outputCol='features')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "reg_train_df = training_assembler.transform(df_train.select(*inputColumns)).select('features', *target)\n",
    "reg_test_df = test_assembler.transform(df_test.select(*inputColumns)).select('features', *target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "clf_train_df.toPandas().to_csv('data/clf_train.csv')\n",
    "clf_test_df.toPandas().to_csv('data/clf_test.csv')\n",
    "\n",
    "reg_train_df.toPandas().to_csv('data/reg_train.csv')\n",
    "reg_test_df.toPandas().to_csv('data/reg_test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}