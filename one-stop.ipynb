{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup Environment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def init_spark():\n",
    "    return SparkSession \\\n",
    "        .builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"Chess Preprocess\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark = init_spark()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "seed = 42"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = spark.read.csv('data/games.csv', header=True, inferSchema=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Inspection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "         id  rated    created_at  last_move_at  turns victory_status winner  \\\n0  TZJHLljE  False  1.504210e+12  1.504210e+12     13      outoftime  white   \n1  l1NXvwaE   True  1.504130e+12  1.504130e+12     16         resign  black   \n2  mIICvQHh   True  1.504130e+12  1.504130e+12     61           mate  white   \n3  kWKvrqYL   True  1.504110e+12  1.504110e+12     61           mate  white   \n4  9tXo1AUZ   True  1.504030e+12  1.504030e+12     95           mate  white   \n\n  increment_code       white_id  white_rating      black_id  black_rating  \\\n0           15+2       bourgris          1500          a-00          1191   \n1           5+10           a-00          1322     skinnerua          1261   \n2           5+10         ischia          1496          a-00          1500   \n3           20+0  daniamurashov          1439  adivanov2009          1454   \n4           30+3      nik221107          1523  adivanov2009          1469   \n\n                                               moves opening_eco  \\\n0  d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...         D10   \n1  d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...         B00   \n2  e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...         C20   \n3  d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...         D02   \n4  e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...         C41   \n\n                             opening_name  opening_ply  \n0        Slav Defense: Exchange Variation            5  \n1  Nimzowitsch Defense: Kennedy Variation            4  \n2   King's Pawn Game: Leonardis Variation            3  \n3  Queen's Pawn Game: Zukertort Variation            3  \n4                        Philidor Defense            5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>rated</th>\n      <th>created_at</th>\n      <th>last_move_at</th>\n      <th>turns</th>\n      <th>victory_status</th>\n      <th>winner</th>\n      <th>increment_code</th>\n      <th>white_id</th>\n      <th>white_rating</th>\n      <th>black_id</th>\n      <th>black_rating</th>\n      <th>moves</th>\n      <th>opening_eco</th>\n      <th>opening_name</th>\n      <th>opening_ply</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TZJHLljE</td>\n      <td>False</td>\n      <td>1.504210e+12</td>\n      <td>1.504210e+12</td>\n      <td>13</td>\n      <td>outoftime</td>\n      <td>white</td>\n      <td>15+2</td>\n      <td>bourgris</td>\n      <td>1500</td>\n      <td>a-00</td>\n      <td>1191</td>\n      <td>d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...</td>\n      <td>D10</td>\n      <td>Slav Defense: Exchange Variation</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>l1NXvwaE</td>\n      <td>True</td>\n      <td>1.504130e+12</td>\n      <td>1.504130e+12</td>\n      <td>16</td>\n      <td>resign</td>\n      <td>black</td>\n      <td>5+10</td>\n      <td>a-00</td>\n      <td>1322</td>\n      <td>skinnerua</td>\n      <td>1261</td>\n      <td>d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...</td>\n      <td>B00</td>\n      <td>Nimzowitsch Defense: Kennedy Variation</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>mIICvQHh</td>\n      <td>True</td>\n      <td>1.504130e+12</td>\n      <td>1.504130e+12</td>\n      <td>61</td>\n      <td>mate</td>\n      <td>white</td>\n      <td>5+10</td>\n      <td>ischia</td>\n      <td>1496</td>\n      <td>a-00</td>\n      <td>1500</td>\n      <td>e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...</td>\n      <td>C20</td>\n      <td>King's Pawn Game: Leonardis Variation</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>kWKvrqYL</td>\n      <td>True</td>\n      <td>1.504110e+12</td>\n      <td>1.504110e+12</td>\n      <td>61</td>\n      <td>mate</td>\n      <td>white</td>\n      <td>20+0</td>\n      <td>daniamurashov</td>\n      <td>1439</td>\n      <td>adivanov2009</td>\n      <td>1454</td>\n      <td>d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...</td>\n      <td>D02</td>\n      <td>Queen's Pawn Game: Zukertort Variation</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9tXo1AUZ</td>\n      <td>True</td>\n      <td>1.504030e+12</td>\n      <td>1.504030e+12</td>\n      <td>95</td>\n      <td>mate</td>\n      <td>white</td>\n      <td>30+3</td>\n      <td>nik221107</td>\n      <td>1523</td>\n      <td>adivanov2009</td>\n      <td>1469</td>\n      <td>e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...</td>\n      <td>C41</td>\n      <td>Philidor Defense</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas().head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inspect Datatypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[('id', 'string'),\n ('rated', 'boolean'),\n ('created_at', 'double'),\n ('last_move_at', 'double'),\n ('turns', 'int'),\n ('victory_status', 'string'),\n ('winner', 'string'),\n ('increment_code', 'string'),\n ('white_id', 'string'),\n ('white_rating', 'int'),\n ('black_id', 'string'),\n ('black_rating', 'int'),\n ('moves', 'string'),\n ('opening_eco', 'string'),\n ('opening_name', 'string'),\n ('opening_ply', 'int')]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "categorical = [feature for feature, dtype in df.dtypes if dtype in {'string', 'boolean'}]\n",
    "numerical = [feature for feature, dtype in df.dtypes if dtype in {'double', 'int'}]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Numerical Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_at          :13151 unique values\n",
      "last_move_at        :13186 unique values\n",
      "turns               :211 unique values\n",
      "white_rating        :1516 unique values\n",
      "black_rating        :1521 unique values\n",
      "opening_ply         :[28, 12, 1, 13, 6, 16, 3, 20, 5, 19, 15, 9, 17, 4, 8, 7, 10, 11, 14, 2, 18, 22, 24]\n"
     ]
    }
   ],
   "source": [
    "for col in numerical:\n",
    "    unique_values = df.select(col).distinct()\n",
    "    n_unique = unique_values.count()\n",
    "    if n_unique < 50:\n",
    "        print(f'{col:20s}:{[row[col] for row in unique_values.collect()]}')\n",
    "    else:\n",
    "        print(f'{col:20s}:{n_unique} unique values')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- `created_at`: Timestamp in UTC\n",
    "- `last_move_at`: Timestamp in UTC\n",
    "- `turns`: Number of turns in the match\n",
    "- `white_rating`: white player rating\n",
    "- `black_rating`: black player rating\n",
    "- `opening_ply`: Number of plies used to set up opening"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Categorical Features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                  :19113 unique values\n",
      "rated               :[True, False]\n",
      "victory_status      :['resign', 'outoftime', 'mate', 'draw']\n",
      "winner              :['white', 'black', 'draw']\n",
      "increment_code      :400 unique values\n",
      "white_id            :9438 unique values\n",
      "black_id            :9331 unique values\n",
      "moves               :18920 unique values\n",
      "opening_eco         :365 unique values\n",
      "opening_name        :1477 unique values\n"
     ]
    }
   ],
   "source": [
    "for col in categorical:\n",
    "    unique_values = df.select(col).distinct()\n",
    "    n_unique = unique_values.count()\n",
    "    if n_unique < 50:\n",
    "        print(f'{col:20s}:{[row[col] for row in unique_values.collect()]}')\n",
    "    else:\n",
    "        print(f'{col:20s}:{n_unique} unique values')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- `id`: Game ID, uniquely identifies a match record\n",
    "- `rated`: If rated, the game result affects player ratings\n",
    "- `victory_status`: How the game ended\n",
    "- `winner`: Match winner\n",
    "- `increment_code`: Game time setting\n",
    "- `white_id`: white player id\n",
    "- `black_id`: black player id\n",
    "- `moves`: Sequence of moves recorded during the match\n",
    "- `opening_eco`: ECO classification code for the chess openings moves\n",
    "- `opening_name`: Name of opening moves"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview of the Target Columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|winner|count|\n",
      "+------+-----+\n",
      "| white|10001|\n",
      "| black| 9107|\n",
      "|  draw|  950|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('winner').count().show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|      black_rating|      white_rating|       rating_diff|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|             20058|             20058|             20058|\n",
      "|   mean|1588.8319872370128|1596.6318675840064|-7.799880346993718|\n",
      "| stddev| 291.0361259603342|291.25337573701825|249.03666666007965|\n",
      "|    min|               789|               784|             -1499|\n",
      "|    max|              2723|              2700|              1605|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('rating_diff', df.black_rating - df.white_rating).describe('black_rating', 'white_rating', 'rating_diff').show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Look for Anomalies"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique samples / total samples: 19629 / 20058 \n"
     ]
    }
   ],
   "source": [
    "print( f'unique samples / total samples: {df.distinct().count()} / {df.count()} ' )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Null Values in each Column\n"
     ]
    },
    {
     "data": {
      "text/plain": "   id  rated  created_at  last_move_at  turns  victory_status  winner  \\\n0   0      0           0             0      0               0       0   \n\n   increment_code  white_id  white_rating  black_id  black_rating  moves  \\\n0               0         0             0         0             0      0   \n\n   opening_eco  opening_name  opening_ply  \n0            0             0            0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>rated</th>\n      <th>created_at</th>\n      <th>last_move_at</th>\n      <th>turns</th>\n      <th>victory_status</th>\n      <th>winner</th>\n      <th>increment_code</th>\n      <th>white_id</th>\n      <th>white_rating</th>\n      <th>black_id</th>\n      <th>black_rating</th>\n      <th>moves</th>\n      <th>opening_eco</th>\n      <th>opening_name</th>\n      <th>opening_ply</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Count Null Values in each Column')\n",
    "df.select([F.count(F.when(F.isnull(col), col)).alias(col) for col in df.columns]).toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- There are duplicate rows, which should be dropped from the dataset.\n",
    "- Luckily, this dataset does not contain missing values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preparation (Preprocessing)\n",
    "Scikit-Learn offers a range of useful methods for preprocessing and data splits. With the approval from the course instructor, we will transform the datasets into *Pandas DataFrames* in this part."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fix Anomalies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Drop Duplicates\n",
    "df = df.distinct()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Label `winner`\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|winner|winner_label|\n",
      "+------+------------+\n",
      "|  draw|         2.0|\n",
      "| white|         0.0|\n",
      "| black|         1.0|\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_indexer = StringIndexer(inputCol='winner', outputCol='winner_label')\n",
    "label_indexer_model = label_indexer.fit(df)\n",
    "df = label_indexer_model.transform(df)\n",
    "df.select('winner', 'winner_label').distinct().show()\n",
    "df = df.drop('winner').withColumnRenamed('winner_label', 'winner')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature `increment_code`\n",
    "As per inspection, the feature contains a string with two numbers separated by `+`. After research, we found that the first number refers to initial total clock time per player in *minutes*; the second number refers to the number of *seconds* added to the total clock time after the player makes a move. We decided to extract these two numbers as two separate features `clock` and `increment` replacing `increment_code`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(increment_code='30+25'),\n Row(increment_code='10+0'),\n Row(increment_code='10+3')]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('increment_code').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(clock=5, increment=60),\n Row(clock=8, increment=0),\n Row(clock=3, increment=10)]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = F.split(df.increment_code, '[+]')\n",
    "df = df.withColumn('clock', splits.getItem(0).cast('Integer')).withColumn('increment', splits.getItem(1).cast('Integer'))\n",
    "df.select('clock', 'increment').tail(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature `opening_eco`\n",
    "As per inspection, each row of this feature is a concatenation of a letter that denotes an [opening moves category](https://www.365chess.com/eco.php). Although there are variations within each category, we assume that the opening moves in each category to be similar enough that we can ignore the differences within each opening move category. Therefore, we extract the first letter from `opening_eco` to a new feature `open_cat` and ignore `opening_eco` during training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "[Row(opening_eco='B11'), Row(opening_eco='B45'), Row(opening_eco='C60')]"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('opening_eco').head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|open_category|\n",
      "+-------------+\n",
      "|            E|\n",
      "|            B|\n",
      "|            D|\n",
      "|            C|\n",
      "|            A|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('open_category', df.opening_eco.substr(0, 1))\n",
    "df.select('open_category').distinct().show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|open_category|open_cat|\n",
      "+-------------+--------+\n",
      "|            D|     3.0|\n",
      "|            B|     1.0|\n",
      "|            E|     4.0|\n",
      "|            C|     0.0|\n",
      "|            A|     2.0|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "open_cat_indexer = StringIndexer(inputCol='open_category', outputCol='open_cat')\n",
    "open_cat_model = open_cat_indexer.fit(df)\n",
    "df = open_cat_model.transform(df)\n",
    "df.select('open_category', 'open_cat').distinct().show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature `rated`\n",
    "Contains boolean values only and does not require preprocessing. Rated games affect player ratings and may affect performance of the player. We may choose to separate rated games from unrated games for this fact, here we did not."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split into Train/Test Sets\n",
    "1. Encode player ids into numerical values.\n",
    "    - Ensure that each player is assigned one and only one numerical id.\n",
    "2. Use encoded player ids to split dataset based on groups.\n",
    "    - Each group contains the matches played by one player. Make sure that each group are sampled evenly in the training set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scikit-Learn Split methods cannot handle distributed datasets. Because we want to leverage the `GroupSplit` method in Scikit-Learn, we are turning the Spark DF into Pandas DF."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "df_pd = df.toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encode categorical player `white_id`s `black_id`s to split based on individual players"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "                  white_id  white_id_num        black_id  black_id_num\n0                 konst767             0    ducksandcats             1\n1      everybodylovesjesus             2          ahmd11             3\n2                 jeff1983             4       bekzodjon             5\n3                 mellowg7             6        jesteroz             7\n4                 omnivoid             8  hasan_al-banna             9\n...                    ...           ...             ...           ...\n19624     demontechristo66          9751           eie24          2797\n19625         r-mohamadi55         15633           eie24          2797\n19626           kastorcito          4761            ed84          3240\n19627                 ssf7          2561            casr         15634\n19628                vares          3149        seciyeli          5683\n\n[19629 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>white_id</th>\n      <th>white_id_num</th>\n      <th>black_id</th>\n      <th>black_id_num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>konst767</td>\n      <td>0</td>\n      <td>ducksandcats</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>everybodylovesjesus</td>\n      <td>2</td>\n      <td>ahmd11</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>jeff1983</td>\n      <td>4</td>\n      <td>bekzodjon</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mellowg7</td>\n      <td>6</td>\n      <td>jesteroz</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>omnivoid</td>\n      <td>8</td>\n      <td>hasan_al-banna</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19624</th>\n      <td>demontechristo66</td>\n      <td>9751</td>\n      <td>eie24</td>\n      <td>2797</td>\n    </tr>\n    <tr>\n      <th>19625</th>\n      <td>r-mohamadi55</td>\n      <td>15633</td>\n      <td>eie24</td>\n      <td>2797</td>\n    </tr>\n    <tr>\n      <th>19626</th>\n      <td>kastorcito</td>\n      <td>4761</td>\n      <td>ed84</td>\n      <td>3240</td>\n    </tr>\n    <tr>\n      <th>19627</th>\n      <td>ssf7</td>\n      <td>2561</td>\n      <td>casr</td>\n      <td>15634</td>\n    </tr>\n    <tr>\n      <th>19628</th>\n      <td>vares</td>\n      <td>3149</td>\n      <td>seciyeli</td>\n      <td>5683</td>\n    </tr>\n  </tbody>\n</table>\n<p>19629 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_ids = pd.DataFrame(df_pd[['white_id', 'black_id']])\n",
    "player_ids = player_ids.stack().pipe(lambda s: pd.Series(pd.factorize(s.values)[0], s.index)).unstack()\n",
    "\n",
    "df_pd['white_id_num'] = player_ids['white_id']\n",
    "df_pd['black_id_num'] = player_ids['black_id']\n",
    "\n",
    "df_pd[['white_id', 'white_id_num', 'black_id', 'black_id_num']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "train_idx, test_idx = next(gss.split(df_pd, df_pd['winner'], groups=df_pd['white_id_num']))\n",
    "\n",
    "df_train = df_pd.iloc[train_idx]\n",
    "\n",
    "df_test = df_pd.iloc[test_idx]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Proof that none of the IDs from the training set are present in the test set.\n",
    "df_train_values = set(df_train['white_id'].values)\n",
    "df_test_values = set(df_test['white_id'].values)\n",
    "\n",
    "assert len(df_train_values.intersection(df_test_values)) == 0, 'A group is present in both training and test sets'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature `victory_status`\n",
    "From inspection, we observe 4 unique values for this categorical feature: `'resign', 'outoftime', 'mate', 'draw'`. We perform one-hot encoding before feeding this into the model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['status_draw', 'status_mate', 'status_outoftime', 'status_resign'],\n      dtype=object)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OneHotEncoder(sparse=False, dtype=int, handle_unknown='ignore')\n",
    "enc.fit(df_train['victory_status'].to_numpy().reshape(-1, 1))\n",
    "encoded_feature_names = 'status_' + enc.categories_[0]\n",
    "encoded_feature_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuxiang\\AppData\\Local\\Temp\\ipykernel_18684\\2844110880.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train.loc[:,encoded_feature_names] = one_hot_status\n",
      "C:\\Users\\yuxiang\\AppData\\Local\\Temp\\ipykernel_18684\\2844110880.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test.loc[:,encoded_feature_names] = one_hot_status\n"
     ]
    },
    {
     "data": {
      "text/plain": "   status_draw  status_mate  status_outoftime  status_resign\n0            0            0                 0              1\n1            0            0                 0              1\n3            0            1                 0              0\n4            0            0                 0              1\n6            0            0                 0              1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>status_draw</th>\n      <th>status_mate</th>\n      <th>status_outoftime</th>\n      <th>status_resign</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_status = enc.transform(df_train['victory_status'].to_numpy().reshape(-1, 1))\n",
    "df_train.loc[:,encoded_feature_names] = one_hot_status\n",
    "\n",
    "one_hot_status = enc.transform(df_test['victory_status'].to_numpy().reshape(-1, 1))\n",
    "df_test.loc[:,encoded_feature_names] = one_hot_status\n",
    "df_train[encoded_feature_names].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Spark DF from Pandas DF Train/Test Set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "df_train = spark.createDataFrame(df_train)\n",
    "\n",
    "df_test = spark.createDataFrame(df_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature `moves`\n",
    "As per inspection, this feature records the list/sequence of moves during the match. Because that the sequence, if parsed correctly, actually indicates the winning player, we need to either drop this feature or obfuscate this information. We find that Spark supports Word2Vec feature transformation, which will turn the sequence into a vector. Such vector representation is independent of the order of the moves, and this can obfuscate part of the information lied within this feature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "'e4 c6 Nc3 d5 Nf3 Bg4 h3 Bh5 exd5 cxd5 Bb5+ Nc6 g4 Bg6 Ne5 Qb6 Nxg6 hxg6 Nxd5 Qc5 Qf3 Rc8 Nc3 e6 d3 Qe5+ Qe4 Bd6 Be3 Ne7 Bd4 Qxe4+ Nxe4 Bb8 Bxg7 Rh4 Bf6 Rh6'"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.select('moves').head().moves"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "vectorSize = 100\n",
    "word2Vec = Word2Vec(vectorSize=vectorSize, seed=seed, inputCol=\"moves_list\", outputCol=\"moves_vec\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Parameters for `Word2Vec`\n",
    "- `vectorSize`: size of the output vector, the choice of 100 is arbitrary here\n",
    "- `minCount`: Ignores all words with total frequency lower than this.\n",
    "- `inputCol`: `moves_list` is the input feature, a list of `moves` split by space\n",
    "- `outputCol`: `moves_vec` is the output feature, the transformed vector\n",
    "\n",
    "The Word2Vec model will be trained with the corpus gathered from the `moves` in the training set. After which, it will transform both training and testing datasets' `moves` feature."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "DataFrame[moves_list: array<string>]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split moves from string into list of strings, moves -> [move, move, ...]\n",
    "train_moves_corpus = df_train.select(F.split(df_train.moves, '\\s', -1).alias('moves_list'))\n",
    "train_moves_corpus #.collect()[0][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Word2Vec Model\n",
      "+-----+--------------------+\n",
      "| word|              vector|\n",
      "+-----+--------------------+\n",
      "| Bxd2|[0.03784444555640...|\n",
      "| Nxf6|[-0.0433502122759...|\n",
      "|  a2+|[-0.0110232504084...|\n",
      "|Bxd5+|[-0.1207058131694...|\n",
      "|  Kg8|[-0.2441164255142...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\miniconda3\\envs\\bigdata\\lib\\site-packages\\pyspark\\sql\\context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fitted_word2Vec = word2Vec.fit(train_moves_corpus)\n",
    "print('Trained Word2Vec Model')\n",
    "fitted_word2Vec.getVectors().show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "('Transformed Moves for the 1st Match in Training Set: ',\n DenseVector([0.1189, 0.0334, 0.0764, 0.088, -0.0768, -0.1057, -0.053, 0.0948, -0.0884, 0.1611, -0.0874, 0.0679, -0.0109, 0.0206, -0.0088, 0.0088, 0.015, -0.02, -0.0704, 0.0886, 0.011, -0.0376, 0.0053, -0.0533, -0.0213, -0.0432, -0.0297, -0.1077, -0.0662, -0.0294, -0.0033, 0.0685, -0.0279, -0.0462, 0.1152, 0.0085, -0.0018, 0.1285, -0.0405, -0.0561, -0.0272, -0.0593, 0.0279, -0.073, -0.0607, -0.0779, -0.0512, 0.1071, -0.0009, 0.0791, -0.0241, 0.0591, -0.0326, 0.0043, -0.0869, 0.0118, 0.0989, -0.0697, -0.0492, 0.0123, 0.0241, 0.0614, -0.0494, 0.085, -0.0092, 0.0033, -0.0021, -0.028, -0.0105, -0.0827, -0.0209, 0.0174, 0.0342, 0.0279, -0.1004, 0.081, -0.0158, -0.038, 0.0575, 0.0743, 0.0389, 0.0053, 0.0953, 0.0102, -0.1004, -0.0179, 0.0377, -0.0043, 0.0852, -0.0397, -0.093, -0.0524, 0.1127, 0.0239, -0.0951, -0.1045, 0.0606, -0.0328, 0.064, -0.0075]))"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Transformed Moves for the 1st Match in Training Set: ', fitted_word2Vec.transform(train_moves_corpus).head().moves_vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "df_train = df_train.withColumn('moves_list', F.split(df_train.moves, '\\s', -1))\n",
    "df_train = fitted_word2Vec.transform(df_train)\n",
    "\n",
    "df_test = df_test.withColumn('moves_list', F.split(df_test.moves, '\\s', -1))\n",
    "df_test = fitted_word2Vec.transform(df_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "df_train.toPandas().to_csv('data/train.csv', index=False)\n",
    "df_test.toPandas().to_csv('data/test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification Problem\n",
    " In a new match between two players, who is most likely to win?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "('rated',\n 'turns',\n 'status_draw',\n 'status_mate',\n 'status_resign',\n 'status_outoftime',\n 'clock',\n 'increment',\n 'white_rating',\n 'black_rating',\n 'open_cat',\n 'opening_ply',\n 'moves_vec',\n 'winner')"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = 'rated', 'turns', 'status_draw', 'status_mate', 'status_resign', 'status_outoftime', 'clock', 'increment', 'white_rating', 'black_rating', 'open_cat', 'opening_ply', 'moves_vec'\n",
    "target = 'winner'\n",
    "inputColumns = features + (target,)\n",
    "inputColumns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "training_assembler = VectorAssembler(handleInvalid='error', inputCols=features, outputCol='features')\n",
    "test_assembler = VectorAssembler(handleInvalid='error', inputCols=features, outputCol='features')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "clf_train_df = training_assembler.transform(df_train.select(*inputColumns)).select('features', target)\n",
    "clf_test_df = test_assembler.transform(df_test.select(*inputColumns)).select('features', target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Decision Tree* for Classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=target, featuresCol=\"features\", seed=seed)\n",
    "\n",
    "dtParamGrid = (ParamGridBuilder()\n",
    "               .addGrid(dt.maxDepth, list(range(1, 8)))\n",
    "               .addGrid(dt.maxBins, [4, 8, 16, 32, 64])\n",
    "               .addGrid(dt.minInstancesPerNode, list(range(1, 6)))\n",
    "               .addGrid(dt.impurity, ['gini', 'entropy'])\n",
    "               .build())\n",
    "\n",
    "dtEvaluator = MulticlassClassificationEvaluator(labelCol=target, metricName='f1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From [Spark Docs](https://spark.apache.org/docs/latest/mllib-decision-tree.html#tunable-parameters)\n",
    "- `maxDepth`: Maximum depth of a tree. Deeper trees are more expressive (potentially allowing higher accuracy), but they are also more costly to train and are more likely to overfit.\n",
    "- `minInstancesPerNode`: For a node to be split further, each of its children must receive at least this number of training instances. This is commonly used with RandomForest since those are often trained deeper than individual trees.\n",
    "- `maxBins`: Number of bins used when discretizing continuous features.\n",
    "- `impurity`: Measure of the homogeneity of the labels at the node. (Choice of `gini` and `entropy` for classification)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hyperparameter Tuning (Grid Search)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[1;32mC:\\tools\\miniconda3\\envs\\bigdata\\lib\\multiprocessing\\pool.py:851\u001B[0m, in \u001B[0;36mIMapIterator.next\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    850\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 851\u001B[0m     item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_items\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpopleft\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    852\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m:\n",
      "\u001B[1;31mIndexError\u001B[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [44]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m dtCv \u001B[38;5;241m=\u001B[39m CrossValidator(estimator \u001B[38;5;241m=\u001B[39m dt,\n\u001B[0;32m      2\u001B[0m                       estimatorParamMaps \u001B[38;5;241m=\u001B[39m dtParamGrid,\n\u001B[0;32m      3\u001B[0m                       evaluator \u001B[38;5;241m=\u001B[39m dtEvaluator,\n\u001B[0;32m      4\u001B[0m                       numFolds \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m dtCvModel \u001B[38;5;241m=\u001B[39m \u001B[43mdtCv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclf_train_df\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m bestParamMap \u001B[38;5;241m=\u001B[39m dtCvModel\u001B[38;5;241m.\u001B[39mbestModel\u001B[38;5;241m.\u001B[39mextractParamMap()\n",
      "File \u001B[1;32mC:\\tools\\miniconda3\\envs\\bigdata\\lib\\site-packages\\pyspark\\ml\\base.py:161\u001B[0m, in \u001B[0;36mEstimator.fit\u001B[1;34m(self, dataset, params)\u001B[0m\n\u001B[0;32m    159\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy(params)\u001B[38;5;241m.\u001B[39m_fit(dataset)\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 161\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    164\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mtype\u001B[39m(params))\n",
      "File \u001B[1;32mC:\\tools\\miniconda3\\envs\\bigdata\\lib\\site-packages\\pyspark\\ml\\tuning.py:689\u001B[0m, in \u001B[0;36mCrossValidator._fit\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m    684\u001B[0m train \u001B[38;5;241m=\u001B[39m datasets[i][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mcache()\n\u001B[0;32m    686\u001B[0m tasks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmap\u001B[39m(\n\u001B[0;32m    687\u001B[0m     inheritable_thread_target,\n\u001B[0;32m    688\u001B[0m     _parallelFitTasks(est, train, eva, validation, epm, collectSubModelsParam))\n\u001B[1;32m--> 689\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j, metric, subModel \u001B[38;5;129;01min\u001B[39;00m pool\u001B[38;5;241m.\u001B[39mimap_unordered(\u001B[38;5;28;01mlambda\u001B[39;00m f: f(), tasks):\n\u001B[0;32m    690\u001B[0m     metrics[j] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (metric \u001B[38;5;241m/\u001B[39m nFolds)\n\u001B[0;32m    691\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m collectSubModelsParam:\n",
      "File \u001B[1;32mC:\\tools\\miniconda3\\envs\\bigdata\\lib\\multiprocessing\\pool.py:856\u001B[0m, in \u001B[0;36mIMapIterator.next\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    854\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    855\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m--> 856\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    857\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    858\u001B[0m     item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_items\u001B[38;5;241m.\u001B[39mpopleft()\n",
      "File \u001B[1;32mC:\\tools\\miniconda3\\envs\\bigdata\\lib\\threading.py:302\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    300\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[0;32m    301\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 302\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    303\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "dtCv = CrossValidator(estimator = dt,\n",
    "                      estimatorParamMaps = dtParamGrid,\n",
    "                      evaluator = dtEvaluator,\n",
    "                      numFolds = 5)\n",
    "\n",
    "dtCvModel = dtCv.fit(clf_train_df)\n",
    "\n",
    "bestParamMap = dtCvModel.bestModel.extractParamMap()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Best Parameters found\n",
    "print( ','.join([''.join((param.name, '=', repr(value))) for param, value in bestParamMap.items()]) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use Best Parameters to initialize and train a separate classifier model\n",
    "dtBest = DecisionTreeClassifier(cacheNodeIds=False,checkpointInterval=10,featuresCol='features',impurity='gini',labelCol='winner',leafCol='',maxBins=8,maxDepth=6,maxMemoryInMB=256,minInfoGain=0.0,minInstancesPerNode=1,minWeightFractionPerNode=0.0,predictionCol='prediction',probabilityCol='probability',rawPredictionCol='rawPrediction',seed=42)\n",
    "# assert dtBest.extractParamMap() == bestParamMap, 'Check if the input parameters are the best found. '\n",
    "bestModel = dtBest.fit(clf_train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = dtEvaluator.evaluate(bestModel.transform(clf_test_df))\n",
    "'f1 score', score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Logistic Regression*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=target, featuresCol=\"features\")\n",
    "\n",
    "lrParamGrid = (ParamGridBuilder()\n",
    "               .addGrid(lr.regParam, [0.01, 0.1, 0.5, 0.8, 2.0])\n",
    "               .addGrid(lr.elasticNetParam, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "               .addGrid(lr.fitIntercept, [True, False])\n",
    "               .addGrid(lr.maxIter, [10, 30, 50, 70, 100])\n",
    "               .addGrid(lr.standardization, [True, False])\n",
    "               .build())\n",
    "\n",
    "lrEvaluator = MulticlassClassificationEvaluator(labelCol=target, metricName='f1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From [Medium Article by Dhiraj Rai](https://dhiraj-p-rai.medium.com/logistic-regression-in-spark-ml-8a95b5f5434c)\n",
    "- `regParam` the regularization parameter (>= 0). (default: 0.0)\n",
    "- `elasticNetParam` the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
    "- `fitIntercept` whether to fit an intercept term. (default: True)\n",
    "- `maxIter` maximum iteration number.\n",
    "- `standardization` whether to standardize the training features before fitting the model. The coefficients of models will always be returned on the original scale, so it will be transparent for users. (default: True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hyperparameter Tuning (Grid Search)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lrCv = CrossValidator(estimator = lr,\n",
    "                      estimatorParamMaps = lrParamGrid,\n",
    "                      evaluator = lrEvaluator,\n",
    "                      numFolds = 5)\n",
    "\n",
    "lrCvModel = lrCv.fit(clf_train_df)\n",
    "\n",
    "bestParamMap = lrCvModel.bestModel.extractParamMap()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Best Parameters found\n",
    "print( ','.join([''.join((param.name, '=', repr(value))) for param, value in bestParamMap.items()]) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lrBest = LogisticRegression(aggregationDepth=2,elasticNetParam=0.0,family='auto',featuresCol='features',fitIntercept=True,labelCol='winner',maxBlockSizeInMB=0.0,maxIter=70,predictionCol='prediction',probabilityCol='probability',rawPredictionCol='rawPrediction',regParam=0.0,standardization=True,threshold=0.5,tol=1e-06)\n",
    "assert lrBest.extractParamMap() == bestParamMap, 'Check if the input parameters are the best found. '\n",
    "bestModel = lrBest.fit(clf_train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'f1 score', lrEvaluator.evaluate(bestModel.transform(clf_test_df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "The LogisticRegression performs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regression Problem\n",
    " Can a player's rating be determined from a single match record with another player?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = 'rated', 'turns', 'status_draw', 'status_mate', 'status_resign', 'status_outoftime', 'clock', 'increment', 'open_cat', 'opening_ply', 'moves_vec', 'winner', #'white_rating',\n",
    "target = 'black_rating'\n",
    "inputColumns = features + (target,)\n",
    "inputColumns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_assembler = VectorAssembler(handleInvalid='error', inputCols=features, outputCol='features')\n",
    "test_assembler = VectorAssembler(handleInvalid='error', inputCols=features, outputCol='features')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_train_df = training_assembler.transform(df_train.select(*inputColumns)).select('features', target)\n",
    "reg_test_df = test_assembler.transform(df_test.select(*inputColumns)).select('features', target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Selection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor, LinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Decision Tree* for Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(labelCol=target, featuresCol=\"features\", seed=seed)\n",
    "\n",
    "dtParamGrid = (ParamGridBuilder()\n",
    "               .addGrid(dt.maxDepth, list(range(1, 8)))\n",
    "               .addGrid(dt.maxBins, [4, 8, 16, 32, 64])\n",
    "               .addGrid(dt.minInstancesPerNode, list(range(1, 5 + 1)))\n",
    "               .build())\n",
    "\n",
    "dtEvaluator = RegressionEvaluator(labelCol=target, metricName='rmse')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From [Spark Docs](https://spark.apache.org/docs/latest/mllib-decision-tree.html#tunable-parameters)\n",
    "- `maxDepth`: Maximum depth of a tree. Deeper trees are more expressive (potentially allowing higher accuracy), but they are also more costly to train and are more likely to overfit.\n",
    "- `minInstancesPerNode`: For a node to be split further, each of its children must receive at least this number of training instances. This is commonly used with RandomForest since those are often trained deeper than individual trees.\n",
    "- `maxBins`: Number of bins used when discretizing continuous features.\n",
    "- `impurity`: Impurity measure used to choose between candidate splits. (Only `variance` for regression)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hyperparameter Tuning (Grid Search)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dtCv = CrossValidator(estimator = dt,\n",
    "                      estimatorParamMaps = dtParamGrid,\n",
    "                      evaluator = dtEvaluator,\n",
    "                      numFolds = 5)\n",
    "\n",
    "dtCvModel = dtCv.fit(reg_train_df)\n",
    "\n",
    "bestParamMap = dtCvModel.bestModel.extractParamMap()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Best Parameters found\n",
    "print( ','.join([''.join((param.name, '=', repr(value))) for param, value in bestParamMap.items()]) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Use Best Parameters to initialize and train a separate classifier model\n",
    "dtBest = DecisionTreeRegressor(cacheNodeIds=False,checkpointInterval=10,featuresCol='features',impurity='variance',labelCol='black_rating',leafCol='',maxBins=16,maxDepth=5,maxMemoryInMB=256,minInfoGain=0.0,minInstancesPerNode=1,minWeightFractionPerNode=0.0,predictionCol='prediction',seed=42)\n",
    "# assert dtBest.extractParamMap() == bestParamMap, 'Check if the input parameters are the best found. '\n",
    "bestModel = dtBest.fit(reg_train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score = dtEvaluator.evaluate(bestModel.transform(reg_test_df))\n",
    "'rmse', score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The RMSE score is very close to the standard deviation of the difference between `black_rating` and `white_rating`. If the model is given the `white_rating` feature, the RMSE would see a decrease of about 40, further improving the model prediction."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### *Linear Regression*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lr = LinearRegression(labelCol=target, featuresCol=\"features\")\n",
    "\n",
    "lrParamGrid = (ParamGridBuilder()\n",
    "               .addGrid(lr.regParam, [0.01, 0.1, 0.5, 0.8, 2.0]).addGrid(lr.solver, ['auto', 'normal', 'l-bfgs'])\n",
    "               .addGrid(lr.elasticNetParam, [0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "               .addGrid(lr.fitIntercept, [True, False])\n",
    "               .addGrid(lr.maxIter, [5, 10, 30, 50, 70, 100])\n",
    "               .addGrid(lr.standardization, [True, False])\n",
    "               .build())\n",
    "\n",
    "lrEvaluator = RegressionEvaluator(labelCol=target, metricName='rmse')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From [Medium Article by Dhiraj Rai](https://dhiraj-p-rai.medium.com/logistic-regression-in-spark-ml-8a95b5f5434c)\n",
    "- `regParam` the regularization parameter (>= 0). (default: 0.0)\n",
    "- `elasticNetParam` the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
    "- `fitIntercept` whether to fit an intercept term. (default: True)\n",
    "- `maxIter` maximum iteration number.\n",
    "- `standardization` whether to standardize the training features before fitting the model. The coefficients of models will always be returned on the original scale, so it will be transparent for users. (default: True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hyperparameter Tuning (Grid Search)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lrCv = CrossValidator(estimator = lr,\n",
    "                      estimatorParamMaps = lrParamGrid,\n",
    "                      evaluator = lrEvaluator,\n",
    "                      numFolds = 5)\n",
    "\n",
    "lrCvModel = lrCv.fit(reg_train_df)\n",
    "\n",
    "bestParamMap = lrCvModel.bestModel.extractParamMap()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Best Parameters found\n",
    "print( ','.join([''.join((param.name, '=', repr(value))) for param, value in bestParamMap.items()]) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lrBest = LinearRegression(aggregationDepth=2,elasticNetParam=0.0,epsilon=1.35,featuresCol='features',fitIntercept=True,labelCol='black_rating',loss='squaredError',maxBlockSizeInMB=0.0,maxIter=5,predictionCol='prediction',regParam=0.1,solver='auto',standardization=False,tol=1e-06)\n",
    "# assert lrBest.extractParamMap() == bestParamMap, 'Check if the input parameters are the best found. '\n",
    "bestModel = lrBest.fit(reg_train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'rmse score', lrEvaluator.evaluate(bestModel.transform(reg_test_df))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Similarly to DecisionTreeRegressor, the RMSE score is very close to the standard deviation of the difference between `black_rating` and `white_rating`. If the model is given the `white_rating` feature, the RMSE would see a decrease of about 40, further improving the model prediction."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}